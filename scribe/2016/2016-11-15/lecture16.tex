\documentclass[twoside]{article}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

\usepackage{graphicx}
\usepackage{url}

%
% The following commands sets up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}
\newcommand{\dnl}{\mbox{}\par}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[4]{
  \pagestyle{myheadings}
  \thispagestyle{plain}
  \newpage
  \setcounter{lecnum}{#1}
  \setcounter{page}{1}
  \noindent
  \begin{center}
  \framebox{
     \vbox{\vspace{2mm}
   \hbox to 6.28in { {\bf COMPSCI~590S~~~Systems for Data Science
                       \hfill Fall 2016} }
      \vspace{4mm}
      \hbox to 6.28in { {\Large \hfill Lecture #1: #2  \hfill} }
      \vspace{2mm}
      \hbox to 6.28in { {\it Lecturer: #3 \hfill Scribe(s): #4} }
     \vspace{2mm}}
  }
  \end{center}
  \markboth{Lecture {#1}: #2}{Lecture {#1}: #2}
  \vspace*{4mm}
}

%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
%
\renewcommand{\cite}[1]{[#1]}

% \input{epsf}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{FIGURE-SIZE}{CAPTION}{FILENAME}
\newcommand{\fig}[4]{
           \vspace{0.2 in}
           \setlength{\epsfxsize}{#2}
           \centerline{\epsfbox{#4}}
           \begin{center}
           Figure \thelecnum.#1:~#3
           \end{center}
   }

% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}

% Some useful equation alignment commands, borrowed from TeX
\makeatletter
\def\eqalign#1{\,\vcenter{\openup\jot\m@th
 \ialign{\strut\hfil$\displaystyle{##}$&$\displaystyle{{}##}$\hfil
     \crcr#1\crcr}}\,}
\def\eqalignno#1{\displ@y \tabskip\@centering
 \halign to\displaywidth{\hfil$\displaystyle{##}$\tabskip\z@skip
   &$\displaystyle{{}##}$\hfil\tabskip\@centering
   &\llap{$##$}\tabskip\z@skip\crcr
   #1\crcr}}
\def\leqalignno#1{\displ@y \tabskip\@centering
 \halign to\displaywidth{\hfil$\displaystyle{##}$\tabskip\z@skip
   &$\displaystyle{{}##}$\hfil\tabskip\@centering
   &\kern-\displaywidth\rlap{$##$}\tabskip\displaywidth\crcr
   #1\crcr}}
\makeatother

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:



% Some general latex examples and examples making use of the
% macros follow.

\begin{document}

%FILL IN THE RIGHT INFO.
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}

\lecture{16}{Scalability and COST Metrics}{Emery Berger}{Anna Deng,}

\section{What is COST?}

COST is a measurement of how much performance overhead that should be paid compare to a single threaded implementation on one node. It turns out that a single threaded implementation could run the workloads discussed in paper in a hundredth of the time. That means, 100 cores can match up with a single node.

\section{Good or Bad Metric?}
\subsection{Bad Metric}
COST Metrics are bad because most of the times the systems are designed to have other features. For example, COST Metrics does not take the following into account:

\begin{itemize}
\item Fault tolerance
\item Size
\item Availability
\item Network bandwidth
\end{itemize}

Gustafson's Law also play a part here. A reminder of the law is that scalability can be unlimited, and it is proportional to the problem sizes.  Problem size is much greater than the number of cores.
\begin{center}
$\Delta \ Problem \ size >> \Delta \ Number \ of \ cores$
\end{center}


A question of does the system scale to really large workloads? And how big can the size of the workloads be? 
The size of the workload can be determined by RAM, Disk, CPU and cache. Network does no not fit here, but it has a role in terms of serving people. 


For Pregel, disk does not matter except during graph loading. RAM and CPU power does matter a lot.

\subsection{Cache Consistency}
Cache consistency for large workloads are never going to be a problem.
Processor chips are set up to have many cores, and each core has its own on-core cache. The cores will share some level of cache and they have to make sure that their copies of cache lines won't go out of sync. This problem is known as Cache Coherence.

In general, if the workloads are embarrassingly parallel, than the number of threads will be proportional to the speedup.

\subsection{Overhead and Speedup}
The observation about overhead and speed up is what's important. It turns out that things get scaled really well if the overhead is really high.

Suppose we have an operation that adds two numbers:
\begin{center}
$ADD\ X\ Y,\ Z$
\end{center}


It is difficult to optimize the single instruction. However, if we have a lot of overheads in addition to the single ADD operation. Like in the following:

\begin{center}
$For\ i\ in\ range(1,100...00)$ 
\end{center}
\begin{center}
$x=x$ 
\end{center}

This can speed up a lot with multiple threads. Each thread can operate on a different range such that the work are spread out evenly across these threads. As more threads are added, speedup is scaled up much towards linear.
But the overhead is not the core of the problem, because it is garbage and doing nothing valuable.

\section{Hilbert Curve}
In the case of a one-dimensional array, things that are likely to be accessed in the future are located next to each other in order to maximize locality. However, it is not as easy when moving to two dimensions such as a Cartesian Graph in the notion of Matrices.

Hilbert Curve is one of the optimization discussed in the paper. It is also one of the Space Filling Curves with natural locality. The basic idea of a Space Filling Curve is that if the things are divided up into quadrant and When one of the quadrant is visited (fits into RAM/cache), then it will never get out of RAM/Cache until it's done.

\end{document}