\documentclass[twoside]{article}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

\usepackage{graphicx}
\usepackage{url}

%
% The following commands sets up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}
\newcommand{\dnl}{\mbox{}\par}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[4]{
  \pagestyle{myheadings}
  \thispagestyle{plain}
  \newpage
  \setcounter{lecnum}{#1}
  \setcounter{page}{1}
  \noindent
  \begin{center}
  \framebox{
     \vbox{\vspace{2mm}
   \hbox to 6.28in { {\bf CMPSCI~590S~~~Systems for Data Science
                       \hfill Fall 2017} }
      \vspace{4mm}
      \hbox to 6.28in { {\Large \hfill Lecture #1  \hfill} }
%       \hbox to 6.28in { {\Large \hfill Lecture #1: #2  \hfill} }
      \vspace{2mm}
      \hbox to 6.28in { {\it Lecturer: #3 \hfill Scribe: #4} }
     \vspace{2mm}}
  }
  \end{center}
  \markboth{Lecture #1: #2}{Lecture #1: #2}
  \vspace*{4mm}
}

%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
%
\renewcommand{\cite}[1]{[#1]}

% \input{epsf}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{FIGURE-SIZE}{CAPTION}{FILENAME}
\newcommand{\fig}[4]{
           \vspace{0.2 in}
           \setlength{\epsfxsize}{#2}
           \centerline{\epsfbox{#4}}
           \begin{center}
           Figure \thelecnum.#1:~#3
           \end{center}
   }

% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}

% Some useful equation alignment commands, borrowed from TeX
\makeatletter
\def\eqalign#1{\,\vcenter{\openup\jot\m@th
 \ialign{\strut\hfil$\displaystyle{##}$&$\displaystyle{{}##}$\hfil
     \crcr#1\crcr}}\,}
\def\eqalignno#1{\displ@y \tabskip\@centering
 \halign to\displaywidth{\hfil$\displaystyle{##}$\tabskip\z@skip
   &$\displaystyle{{}##}$\hfil\tabskip\@centering
   &\llap{$##$}\tabskip\z@skip\crcr
   #1\crcr}}
\def\leqalignno#1{\displ@y \tabskip\@centering
 \halign to\displaywidth{\hfil$\displaystyle{##}$\tabskip\z@skip
   &$\displaystyle{{}##}$\hfil\tabskip\@centering
   &\kern-\displaywidth\rlap{$##$}\tabskip\displaywidth\crcr
   #1\crcr}}
\makeatother

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:



% Some general latex examples and examples making use of the
% macros follow.

\begin{document}

%FILL IN THE RIGHT INFO.
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\lecture{26}{Nov 28}{Emery Berger}{Tao Chen, Zhaoduo Wen}

\section{Review of Last Lecture - Effect of Hardwares and Softwares on Performance}
Apparently, both hardwares and softwares have influence on the performance of system. In terms of hardware, CPU, GPU, network, disk, memory and RAM/cache can affect the performance of system. With regard to software, algorithm, programming language/runtime system, OS, architecture (multi threads, multi processes) are factors to the performance. If using multi processes, data share is expensive, while concurrency is one of the problems in multi threads.

\section{Paper1: Making Sense of Performance in Data Analytics Framework}
This paper proposes blocked time analysis for quantifying performance bottlenecks in distributed computation frameworks. It tries to understand the bottlenecks to scale up a distributed computation framework, like CPU bound, I/O bound (disk bound, network bound), etc.. Although the paper finds out CPU (and not I/O) is often the bottleneck, it only carries out experiments on Spark environment, whose key idea is in memory computation.

Acutally, I/O is generally the bottleneck for distributed systems. In the condition that CPUs use shared memory generally takes 100 cycles, but using network I/O generally takes 2 $\sim$ 3 order of magintude slower than shared memory, i.e. 100,000 cycles, because network communication requires copying data through the network.

Remote Direct Memory Access(RDMA) is proposed to solve the problem, super fast especially for small messages. RDMA is a direct memory access (a pointer) from the memory of the source computer into that of destination computer without involving either one's operating system. RDMA requires no copying, so it is generally 1 order of magnitude faster than network I/O, which is 10,000 cycles.

\section{Spark vs Hadoop}
The advantage of Spark is in-memeory computation using RDD. Everything is a transformation from one RDD to another RDD. RDD allows it to efficiently provide fault tolerance by logging the transformations used to build a dataset (its lineage) rather than the actual data.

Question: Is Spark always faster than Hadoop?
Answer: No. Spark is limited by the following two conditions.
\begin{itemize}
  \item Data is too large to fit in RAM
  \item No iterations in the map-reduce job (Spark optimizes iteration)
\end{itemize}
In a nutshell, perfomance of the two models is workload dependent, which is always true.



\section{What leads to straggles}
As pointed out in the paper, GC usually leads to the stragglers. However, it can be solved in a "terrible" way. First, use PL without GC, like C++; Second, don't allocate objects.

The pros and cons of GC are as follows:

Pros
\begin{itemize}
  \item safety (use after free)
  \item no memory leaks. If memory is freed too soon, program might crash; If memory is freed too late, program consumes too much memory.
\end{itemize}

Cons
\begin{itemize}
  \item Pause time: GC takes time which would stop the program temorarily.
  \item Space overhead: The assigned heap size is always larger than the actual size the program really needs. Generally, heap size is 3 $\sim$ 5 times bigger than the actual size.
\end{itemize}

Question: Is there any better GC?
Answer: We have real-time GCs that never pause, but those things are relatively slow. There is always a trade-off that either you get small multiple pauses or a very long pause during GC.

\section{Paper2: Scalability! But at what COST?}
COST stands for Configuration Outperfoms a Single Thread. When we try to measure the scalibility of distributed system, it is important to pick a good baseline. Scaling can be easy if you start at very slow baseline. The rule of thumb is the baseline should be the fastest, state-of-the-art version on one node.

Problems of COST
\begin{enumerate}
  \item Data is too big to fit in memory (RAM).
  \item Data is too big to fit in local disk.
  \item Gustafsonâ€™s Law. The number of CPUs should should scales with the size of problem.
  \item The algorithm on a single core/node may be different from that on multi-cores or multiple nodes.
  \item Fault tolerance problem. Program running on single thread may suffer from single point failure.
  \item The cost of moving data from multiple data sources to a single machine is relatively high.
  \item Graph analysiscs perspective. This paper creates a domain specific programming language, which does not mean the general purpose. (For example, Java, C++, Python are general purpose language. SQL is a domain specific programming language for database. Shell and MapReduce are also the domain specific language.)
\end{enumerate}
\end{document}
